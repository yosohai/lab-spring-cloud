Kafka中创建一个Topic，名称为iris:
cd /d D:\ProgramFiles\kafka_2.12-2.8.1
bin\windows\kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic iris

显示所有Topic的列表：
bin\windows\kafka-topics.bat --list --zookeeper localhost:2181

读取（消费）topic iris中的数据：
cd /d D:\ProgramFiles\kafka_2.12-2.8.1 &
bin\windows\kafka-console-consumer.bat --bootstrap-server 127.0.0.1:9092 --topic iris --from-beginning

cd /d D:\ProgramFiles\kafka_2.12-2.8.1
bin\windows\kafka-console-producer.bat --broker-list 127.0.0.1:9092 --topic iris


进入kafka的安装目录：
1. 查看当前服务器中所有的topic
bin/kafka-topics.sh --zookeeper hadoop102:2181 --list

2. 创建topic
bin/kafka-topics.sh --zookeeper hadoop102:2181 \
--create --replication-factor 3 --partitions 1 --topic first
--topic 定义 topic 名
--replication-factor  定义副本数
--partitions  定义分区数

3. 删除topic
bin/kafka-topics.sh --zookeeper hadoop102:2181 \
--delete --topic first

需要 server.properties 中设置 delete.topic.enable=true 否则只是标记删除或者直接重启

4. 发送消息
bin/kafka-console-producer.sh \
--broker-list hadoop102:9092 --topic first
>hello world
>hello kafka

5. 消费消息
bin/kafka-console-consumer.sh \
--zookeeper hadoop102:2181 --from-beginning --topic first
–from-beginning：会把 first 主题中以往所有的数据都读取出来。根据业务场景选择是否增加该配置。

6. 查看某个topic消息的情况
bin/kafka-topics.sh --zookeeper hadoop102:2181 \
--describe --topic first

Producer数据的写入流程：
1）producer 先从 zookeeper 的 "/brokers/…/state"节点找到该 partition 的leader
2）producer 将消息发送给该 leader
3）leader 将消息写入本地 log
4）followers 从 leader pull 消息，写入本地 log 后向 leader 发送 ACK
5）leader 收到所有 ISR 中的 replication 的 ACK 后，增加 HW（high watermark，最后commit 的 offset）并向 producer 发送 ACK